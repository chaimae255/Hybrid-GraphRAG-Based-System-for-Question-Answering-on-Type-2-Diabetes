{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3c74b3-1ef3-4dbf-b4f0-4c093ba38711",
   "metadata": {},
   "source": [
    "<h4>Installing Required Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61239143-7c65-4716-aa86-e23385e16230",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_core\n",
    "!pip install langchain\n",
    "!pip install langchain_experimental\n",
    "!pip install neo4j\n",
    "!pip install yfiles_jupyter_graphs\n",
    "!pip install PyPDF2\n",
    "!pip install pypdf\n",
    "!pip install requests\n",
    "!pip install py2neo\n",
    "!pip install python-dotenv\n",
    "!pip install langchain langchain_groq pydantic\n",
    "!pip install langchain_community\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d339248-b64a-4f36-9691-ff269db34acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b06fd9-9f76-4a76-bb56-e383fa0860ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "url = \"ENTER YOUR NEO4J URL\"\n",
    "username = \"ENTER YOUR NEO4J USERNAME\"\n",
    "password = \"ENTER YOUR NEO4J PASSWORD\"\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password\n",
    ")\n",
    "\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"API_KEY\"\n",
    "api_key = os.environ['GROQ_API_KEY']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec4944-f2ca-48c6-9bcc-2321a68206a0",
   "metadata": {},
   "source": [
    "<h4> Defining Custom Pydantic Models for Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576de758-3def-45f8-8aa8-b16598557cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.graphs.graph_document import (\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship,\n",
    "    GraphDocument,\n",
    ")\n",
    "from langchain.schema import Document\n",
    "\n",
    "class Property(BaseModel):\n",
    "    \"\"\"A single property consisting of key and value\"\"\"\n",
    "    key: str = Field(..., description=\"key\")\n",
    "    value: str = Field(..., description=\"value\")\n",
    "\n",
    "class Node(BaseNode):\n",
    "    id: str = Field(..., description=\"Unique identifier for the node\")\n",
    "    name: str = Field(..., description=\"Name or title of the node\")\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of node properties\")\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    source: Node = Field(..., description=\"Source node of the relationship\")\n",
    "    target: Node = Field(..., description=\"Target node of the relationship\")\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of relationship properties\"\n",
    "    )\n",
    "    text: str = Field(description=\"Source text from which this relationship was extracted\")\n",
    "\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
    "    nodes: List[Node] = Field(\n",
    "        ..., description=\"List of nodes in the knowledge graph\")\n",
    "    rels: List[Relationship] = Field(\n",
    "        ..., description=\"List of relationships in the knowledge graph\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e8dbaf-9d2b-4b39-bf4b-9a942576898a",
   "metadata": {},
   "source": [
    "<h4> Formatting & Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa96de-202f-481b-86e5-7bbf60b884fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_property_key(s: str) -> str:\n",
    "    words = s.split()\n",
    "    if not words:\n",
    "        return s\n",
    "    first_word = words[0].lower()\n",
    "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
    "    return \"\".join([first_word] + capitalized_words)\n",
    "\n",
    "def props_to_dict(props) -> dict:\n",
    "    \"\"\"Convert properties to a dictionary.\"\"\"\n",
    "    properties = {}\n",
    "    if not props:\n",
    "      return properties\n",
    "    for p in props:\n",
    "        properties[format_property_key(p.key)] = p.value\n",
    "    return properties\n",
    "\n",
    "\n",
    "def map_to_base_node(node: Node) -> BaseNode:\n",
    "    properties = props_to_dict(node.properties) if node.properties else {}\n",
    "    properties[\"name\"] = node.name.strip()  # store the actual entity name\n",
    "    return BaseNode(\n",
    "        id=node.id.strip(),\n",
    "        type=node.type.strip(),\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "\n",
    "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
    "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
    "    source = map_to_base_node(rel.source)\n",
    "    target = map_to_base_node(rel.target)\n",
    "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
    "    return BaseRelationship(\n",
    "        source=source, target=target, type=rel.type, properties=properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b457df-fb77-49dd-afd0-83f447d8584d",
   "metadata": {},
   "source": [
    "<h4> LLM Chain for Knowledge Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e0120-d645-4ad8-9d0d-1c154c096362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "# Core biomedical schema for Type 2 Diabetes\n",
    "ENTITY_TYPES = [\n",
    "    \"Disease\", \"Symptom\", \"Drug\", \"Complication\", \"Biomarker\",\n",
    "    \"RiskFactor\", \"TreatmentProcedure\", \"Gene\", \"MolecularTarget\", \"LifestyleFactor\"\n",
    "]\n",
    "\n",
    "RELATION_TYPES = [\n",
    "    \"treats\", \"causes\", \"associated_with\", \"has_symptom\",\n",
    "    \"contraindicated_with\", \"expresses\", \"linked_to\", \"increases_risk_of\",\n",
    "    \"reduces_risk_of\", \"side_effect_of\"\n",
    "]\n",
    "\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"API_KEY\"\n",
    "\n",
    "def get_extraction_chain_groq(\n",
    "    allowed_nodes: Optional[List[str]] = None,\n",
    "    allowed_rels: Optional[List[str]] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Fonction d'extraction avec prompt sp√©cifiant clairement le format de sortie\n",
    "    \"\"\"\n",
    "\n",
    "    # Parser pour le format KnowledgeGraph\n",
    "    parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "\n",
    "    # System prompt avec exemple de format\n",
    "    system_prompt = PromptTemplate(\n",
    "        template=f\"\"\"\n",
    "You are an expert biomedical knowledge extraction system for constructing a Type 2 Diabetes knowledge graph.\n",
    "Your goal is to extract the **maximum possible medically relevant entities and relationships** from the provided text and output them in the specified JSON format.\n",
    "\n",
    "## STRICT RULES:\n",
    "- You should use ONLY these ENTITY TYPES when possible: {ENTITY_TYPES}\n",
    "- You should use ONLY RELATION TYPES when possible: {RELATION_TYPES}\n",
    "- Entities and relations must be relevant to the biomedical domain (Type 2 Diabetes, treatments, symptoms, comorbidities, drugs, genes, risk factors, lifestyle factors, etc.).\n",
    "- Be consistent: use the exact same spelling for identical entities or relation names for both node 'id' and 'name'. The 'id' and 'name' should usually be the same string representation of the entity.\n",
    "- All relationships must be **medically correct and evidence-based**.\n",
    "\n",
    "\n",
    "## CRITICAL: EXACT OUTPUT FORMAT REQUIRED\n",
    "You MUST follow this EXACT JSON structure. Every field is MANDATORY:\n",
    "\n",
    "Exemple :\n",
    "\n",
    "```json\n",
    "{{{{\n",
    "  \"nodes\": [\n",
    "    {{{{\n",
    "      \"id\": \"Type_2_Diabetes_Mellitus\",\n",
    "      \"name\": \"Type 2 Diabetes Mellitus\",\n",
    "      \"type\": \"Disease\",\n",
    "      \"properties\": []\n",
    "    }}}},\n",
    "    {{{{\n",
    "      \"id\": \"Insulin_Resistance\",\n",
    "      \"name\": \"Insulin resistance\",\n",
    "      \"type\": \"Biomarker\",\n",
    "      \"properties\": []\n",
    "    }}}},\n",
    "    {{{{\n",
    "      \"id\": \"Obesity\",\n",
    "      \"name\": \"Obesity\",\n",
    "      \"type\": \"RiskFactor\",\n",
    "      \"properties\": []\n",
    "    }}}},\n",
    "    {{{{\n",
    "      \"id\": \"Metformin\",\n",
    "      \"name\": \"Metformin\",\n",
    "      \"type\": \"Drug\",\n",
    "      \"properties\": []\n",
    "    }}}},\n",
    "    {{{{\n",
    "      \"id\": \"Diabetic_Nephropathy\",\n",
    "      \"name\": \"Diabetic nephropathy\",\n",
    "      \"type\": \"Complication\",\n",
    "      \"properties\": []\n",
    "    }}}}\n",
    "  ],\n",
    "  \"rels\": [\n",
    "    {{{{\n",
    "      \"source\": {{{{\n",
    "        \"id\": \"Type_2_Diabetes_Mellitus\",\n",
    "        \"name\": \"Type 2 Diabetes Mellitus\",\n",
    "        \"type\": \"Disease\",\n",
    "        \"properties\": []\n",
    "      }}}},\n",
    "      \"target\": {{{{\n",
    "        \"id\": \"Insulin_Resistance\",\n",
    "        \"name\": \"Insulin resistance\",\n",
    "        \"type\": \"Biomarker\",\n",
    "        \"properties\": []\n",
    "      }}}},\n",
    "      \"type\": \"associated_with\",\n",
    "      \"properties\": [],\n",
    "      \"text\": \"Patients with Type 2 Diabetes Mellitus often develop insulin resistance\"\n",
    "    }}}},\n",
    "    {{{{\n",
    "      \"source\": {{{{\n",
    "        \"id\": \"Insulin_Resistance\",\n",
    "        \"name\": \"Insulin resistance\",\n",
    "        \"type\": \"Biomarker\",\n",
    "        \"properties\": []\n",
    "      }}}},\n",
    "      \"target\": {{{{\n",
    "        \"id\": \"Obesity\",\n",
    "        \"name\": \"Obesity\",\n",
    "        \"type\": \"RiskFactor\",\n",
    "        \"properties\": []\n",
    "      }}}},\n",
    "      \"type\": \"associated_with\",\n",
    "      \"properties\": [],\n",
    "      \"text\": \"insulin resistance, which is strongly associated with obesity\"\n",
    "    }}}},\n",
    "    {{{{\n",
    "      \"source\": {{{{\n",
    "        \"id\": \"Hyperglycemia\",\n",
    "        \"name\": \"Hyperglycemia\",\n",
    "        \"type\": \"Biomarker\",\n",
    "        \"properties\": []\n",
    "      }}}},\n",
    "      \"target\": {{{{\n",
    "        \"id\": \"Diabetic_Nephropathy\",\n",
    "        \"name\": \"Diabetic nephropathy\",\n",
    "        \"type\": \"Complication\",\n",
    "        \"properties\": []\n",
    "      }}}},\n",
    "      \"type\": \"leads_to\",\n",
    "      \"properties\": [],\n",
    "      \"text\": \"Prolonged hyperglycemia leads to complications such as diabetic nephropathy\"\n",
    "    }}}},\n",
    "    {{{{\n",
    "      \"source\": {{{{\n",
    "        \"id\": \"Metformin\",\n",
    "        \"name\": \"Metformin\",\n",
    "        \"type\": \"Drug\",\n",
    "        \"properties\": []\n",
    "      }}}},\n",
    "      \"target\": {{{{\n",
    "        \"id\": \"Insulin_Resistance\",\n",
    "        \"name\": \"Insulin resistance\",\n",
    "        \"type\": \"Biomarker\",\n",
    "        \"properties\": []\n",
    "      }}}},\n",
    "      \"type\": \"improves\",\n",
    "      \"properties\": [],\n",
    "      \"text\": \"Metformin improves insulin sensitivity\"\n",
    "    }}}}\n",
    "  ]\n",
    "}}}}\n",
    "```\n",
    "\n",
    "## MANDATORY FORMAT RULES:\n",
    "1. Every node MUST have: \"id\", \"name\", \"type\", \"properties\" (even if properties is empty array [])\n",
    "2. Every relationship MUST have: \"source\", \"target\", \"type\", \"properties\"\n",
    "3. Every \"source\" and \"target\" in relationships MUST be complete node objects with \"id\", \"name\", \"type\", \"properties\"\n",
    "4. \"id\" and \"name\" should be identical for each entity\n",
    "5. \"properties\" should be an empty array [] if no properties exist\n",
    "6. DO NOT omit any required fields\n",
    "\n",
    "## ENTITY TYPING GUIDANCE:\n",
    "- Disease = medical condition (Type 2 Diabetes Mellitus)\n",
    "- Symptom = patient-experienced\n",
    "- Complication = consequence of disease\n",
    "- Biomarker = measurable indicator\n",
    "- RiskFactor = predisposing factor\n",
    "- Drug = pharmacologic agent\n",
    "- Gene = genetic factor\n",
    "- MolecularTarget = specific biological target\n",
    "- LifestyleFactor = behavioral or environmental factor\n",
    "\n",
    "##RELATION TYPING GUIDANCE:\n",
    "- Treats = subject is used to cure or manage the object\n",
    "- Causes = subject directly produces or leads to the object\n",
    "- Associated_with = subject and object occur together or correlate, not necessarily causal\n",
    "- Has_symptom = object is a symptom of the subject\n",
    "- Contraindicated_with = subject should not be used with object\n",
    "- Expresses = subject produces or displays the object (e.g., gene ‚Üí protein)\n",
    "- Linked_to = subject and object are connected in a broad or unspecified way\n",
    "- Increases_risk_of = subject raises the likelihood of the object\n",
    "- Reduces_risk_of = subject lowers the likelihood of the object\n",
    "- Side_effect_of = subject is an adverse effect caused by the object\n",
    "\n",
    "\n",
    "\n",
    "Output ONLY the JSON object following the exact format above. Do not include any additional text, explanations, or markdown formatting.\n",
    "\"\"\",\n",
    "        input_variables=[]\n",
    "    )\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate(prompt=system_prompt)\n",
    "\n",
    "    # Human prompt simplifi√©\n",
    "    human_prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "Extract entities and relationships from the following biomedical text about Type 2 Diabetes Mellitus.\n",
    "\n",
    "Follow the exact JSON format specified in the system prompt. Ensure every required field is present.\n",
    "\n",
    "Text: {doc}\n",
    "\n",
    "JSON Output:\n",
    "\"\"\",\n",
    "        input_variables=[\"doc\"]\n",
    "    )\n",
    "\n",
    "    human_message_prompt = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "    # Chat prompt\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "    # Mod√®le Groq\n",
    "    model = ChatGroq(temperature=0, model_name=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "\n",
    "    # Cha√Æne LLM avec parser\n",
    "    chain = chat_prompt | model | parser\n",
    "\n",
    "    return chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d211c-3bf2-42aa-8e9a-9c1dd050e063",
   "metadata": {},
   "source": [
    " <h4>Extract & Store Graph Data into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ec793-5c3e-4f74-b9b3-b90694829b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_store_graph(\n",
    "    document: Document,\n",
    "    nodes: Optional[List[str]] = None,\n",
    "    rels: Optional[List[str]] = None\n",
    ") -> None:\n",
    "    # Extract graph data using the Groq chain\n",
    "    extract_chain = get_extraction_chain_groq(nodes, rels)\n",
    "    kg = extract_chain.invoke({\"doc\": document.page_content})\n",
    "\n",
    "    # Ensure 'nodes' and 'rels' are present in the response\n",
    "    if not hasattr(kg, 'nodes') or not hasattr(kg, 'rels'):\n",
    "        raise ValueError(\"Missing 'nodes' or 'rels' in the extracted KnowledgeGraph object\")\n",
    "\n",
    "    # Construct a graph document\n",
    "    graph_document = GraphDocument(\n",
    "    nodes=[map_to_base_node(node) for node in kg.nodes],\n",
    "    relationships=[map_to_base_relationship(rel) for rel in kg.rels],\n",
    "    source=document\n",
    "    )\n",
    "\n",
    "    # Store information into a graph\n",
    "    print(f\"Adding graph document for: {document.metadata.get('source', 'unknown source')}\")\n",
    "    graph.add_graph_documents([graph_document])\n",
    "    return graph_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb75d3-b883-4ad8-a507-3b599a96727b",
   "metadata": {},
   "source": [
    "<h4> Building the Graph from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196cb95-33a8-42eb-a9b7-0f66cbd6e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 2000\"\"\"\n",
    "\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from datetime import datetime\n",
    "import os\n",
    "from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "folder_path = '/content/drive/MyDrive/Diabetes_KG_Project/2023_1'\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=5000, chunk_overlap=100)\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "for file_name in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    try:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        pages = loader.load()  \n",
    "        full_text = \" \".join([p.page_content for p in pages])\n",
    "        documents = text_splitter.create_documents([full_text])\n",
    "        all_chunks.extend(documents)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "# Processing chunks with tqdm progress bar\n",
    "distinct_nodes = set()\n",
    "relations = []\n",
    "extracted_knowledge_graphs = []\n",
    "\n",
    "for i, d in tqdm(enumerate(all_chunks), total=len(all_chunks), desc=\"Processing Chunks\"):\n",
    "    #graph_document = extract_and_store_graph(d)\n",
    "\n",
    "    #extracted_knowledge_graphs.append(graph_document)\n",
    "\n",
    "    # Get distinct nodes\n",
    "    for node in graph_document.nodes:\n",
    "        distinct_nodes.add(node.id)\n",
    "\n",
    "    # Get all relations\n",
    "    for relation in graph_document.relationships:\n",
    "        relations.append(relation.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a5d459-769a-461b-81e5-74bd2687586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 2023\"\"\"\n",
    "\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from datetime import datetime\n",
    "import os\n",
    "from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "folder_path = '/content/drive/MyDrive/Diabetes_KG_Project/2023_2'\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=5000, chunk_overlap=100)\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "for file_name in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    try:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        pages = loader.load()  \n",
    "        full_text = \" \".join([p.page_content for p in pages])\n",
    "        documents = text_splitter.create_documents([full_text])\n",
    "        all_chunks.extend(documents)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "# Processing chunks with tqdm progress bar\n",
    "distinct_nodes = set()\n",
    "relations = []\n",
    "extracted_knowledge_graphs = []\n",
    "\n",
    "for i, d in tqdm(enumerate(all_chunks), total=len(all_chunks), desc=\"Processing Chunks\"):\n",
    "    #graph_document = extract_and_store_graph(d)\n",
    "\n",
    "    #extracted_knowledge_graphs.append(graph_document)\n",
    "\n",
    "    # Get distinct nodes\n",
    "    for node in graph_document.nodes:\n",
    "        distinct_nodes.add(node.id)\n",
    "\n",
    "    # Get all relations\n",
    "    for relation in graph_document.relationships:\n",
    "        relations.append(relation.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b8f10-f146-43ca-8806-36c3be3e3a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb62479-6a7f-4677-9894-4601f35d5eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9b5d6-3c88-4052-b710-dc19bcf80c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06d023-6811-411b-a177-dad1434ce43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cd3d8cd-8ef3-4645-a605-6090bb0ba5d3",
   "metadata": {},
   "source": [
    "<h4>Visualizing the Knowledge Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05584d96-49ca-44bc-a202-5f3e7ae06dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ditectly show the graph resulting from  the given cypher query\n",
    "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 500\"\n",
    "\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from google.colab import output\n",
    "\n",
    "def showGraph(cypher:str = default_cypher):\n",
    "    # create a neo4j session to run queries\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = url,\n",
    "        auth = (username, password))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
    "    widget.node_label_mapping = \"id\"\n",
    "    # display(widget)\n",
    "    return widget\n",
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b2c95-82ca-4b98-b12f-d72eba71ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = graph.query(\"MATCH (n) RETURN count(n)\")[0]['count(n)']\n",
    "rels = graph.query(\"MATCH ()-[r]->() RETURN count(r)\")[0]['count(r)']\n",
    "print(f\"N≈ìuds: {nodes:,} | Relations: {rels:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d57faba-f639-403d-bda1-a9be2cc2c04e",
   "metadata": {},
   "source": [
    "<h4> LLM-Powered Node Filtering (Clean Irrelevant Nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c60e4-ce8c-4e53-b5ba-00320f0504e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from groq import Groq\n",
    "import json\n",
    "\n",
    "GROQ_API_KEY = \"API_KEY\"\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "driver = GraphDatabase.driver(url, auth=(username, password))\n",
    "\n",
    "def get_nodes_from_label(label: str):\n",
    "    \"\"\"Extract node names from Neo4j for a given label.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    MATCH (n:{label})\n",
    "    RETURN DISTINCT n.name AS node\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        results = session.run(query)\n",
    "        return [record[\"node\"] for record in results if record[\"node\"]]\n",
    "\n",
    "def filter_irrelevant_nodes(label: str, nodes: list):\n",
    "    \"\"\"Ask LLM to identify irrelevant nodes for T2D.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a medical expert specialized in Type 2 Diabetes (T2D).\n",
    "Here is a list of nodes coming from a knowledge graph (category: {label}).\n",
    "\n",
    "Your task is to identify the nodes that:\n",
    "- are NOT medical concepts,\n",
    "- are NOT relevant to Type 2 Diabetes,\n",
    "- or make no medical sense.\n",
    "\n",
    "Return STRICTLY in JSON format only:\n",
    "{{\n",
    "  \"irrelevant_nodes\": [\"Node1\", \"Node2\", ...]\n",
    "}}\n",
    "\n",
    "### Examples:\n",
    "\n",
    "Input List: [Insulin, Glucose metabolism, Car Engine, Guitar, Metformin]\n",
    "Output: {{\"irrelevant_nodes\": [\"Car Engine\", \"Guitar\"]}}\n",
    "\n",
    "Input List: [Obesity, Hypertension, Banana, Blood Pressure, T2D, Chair]\n",
    "Output: {{\"irrelevant_nodes\": [\"Banana\", \"Chair\"]}}\n",
    "\n",
    "Input List: [Diabetes Distress, Depression, Anxiety, Happiness, Leg Pain, iPhone]\n",
    "Output: {{\"irrelevant_nodes\": [\"Happiness\", \"iPhone\"]}}\n",
    "\n",
    "---\n",
    "\n",
    "Now process the following list:\n",
    "\n",
    "List: {nodes}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        irrelevant_nodes = json.loads(result)[\"irrelevant_nodes\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing LLM response:\", e)\n",
    "        irrelevant_nodes = []\n",
    "\n",
    "    return irrelevant_nodes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Enter the label you want to process\n",
    "    label = input(\"Enter the label name (e.g. Symptom, Drug, Treatment): \").strip()\n",
    "\n",
    "    nodes = get_nodes_from_label(label)\n",
    "    print(f\"‚úÖ Extracted {len(nodes)} nodes for label '{label}'\")\n",
    "\n",
    "    irrelevant = filter_irrelevant_nodes(label, nodes)\n",
    "    print(f\"\\nüöÆ Irrelevant nodes suggested for deletion in '{label}':\\n{irrelevant}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3-TF2.0)",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
